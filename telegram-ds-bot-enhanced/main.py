# main.py
import os
import tempfile
import logging
import random
import asyncio
import json
import time
from pathlib import Path
from datetime import datetime
from telegram import Update, InputFile, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes
from telegram.constants import ParseMode
from dotenv import load_dotenv

from data_processor import process_dataset
from report_generator import bundle_outputs
from gpt_summary import generate_gpt_summary
from performance import (monitor_performance, resource_manager, perf_monitor, 
                     cache_manager, check_system_health, timeout_manager)

load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
MAX_FILE_MB = int(os.getenv("MAX_FILE_MB", "20")) * 1024 * 1024

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# User session storage
user_sessions = {}

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_sessions[user_id] = {
        'processing': False,
        'last_analysis': None,
        'preferences': {'include_ml': True, 'include_gpt': True}
    }
    
    welcome_text = """
ğŸ¤– **Welcome to Thedysci Bot!**

I'm your AI-powered data analysis assistant. I can help you:

ğŸ“Š **Analyze your datasets** - Upload CSV/XLSX files
ğŸ” **Generate insights** - Automatic EDA and statistical analysis  
ğŸ¤– **Build ML models** - Classification and regression models
ğŸ“ˆ **Create reports** - Beautiful HTML/PDF reports with visualizations
ğŸ’¡ **AI summaries** - GPT-powered insights and recommendations

**How to use:**
1. Send me a CSV or XLSX file as a document
2. I'll analyze it and send back a comprehensive report
3. Use /settings to customize your analysis preferences

Ready to analyze some data? Just send me a file! ğŸš€
"""
    
    keyboard = [
        [InlineKeyboardButton("ğŸ“Š Upload Dataset", callback_data="upload")],
        [InlineKeyboardButton("âš™ï¸ Settings", callback_data="settings"),
         InlineKeyboardButton("â“ Help", callback_data="help")],
        [InlineKeyboardButton("ğŸ“ˆ Sample Analysis", callback_data="sample")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(welcome_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)

def _is_allowed(filename: str):
    return any(filename.lower().endswith(ext) for ext in (".csv", ".xlsx", ".xls"))

@monitor_performance
async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"handle_file called for user={user_id}")
    
    # Check if we can start a new analysis with enhanced reason
    can_start, reason = await resource_manager.can_start_analysis(user_id)
    if not can_start:
        await update.message.reply_text(f"â³ Cannot start analysis: {reason}\nPlease try again in a few minutes.")
    
    # Check if user is already processing
    if user_id in user_sessions and user_sessions[user_id].get('processing', False):
        await update.message.reply_text("â³ You already have an analysis in progress. Please wait for it to complete.")
        return
    
    msg = update.message
    if not msg or not msg.document:
        await update.message.reply_text("âŒ Please send a file as a document.")
        return

    doc = msg.document
    filename = doc.file_name or "dataset"
    
    # Enhanced file validation
    if doc.file_size and doc.file_size > MAX_FILE_MB:
        await msg.reply_text(f"âŒ File too large! Maximum size is {MAX_FILE_MB // (1024*1024)} MB.\nYour file: {doc.file_size // (1024*1024)} MB")
        return

    if not _is_allowed(filename):
        supported_formats = "`.csv`, `.xlsx`, `.xls`"
        await msg.reply_text(f"âŒ Unsupported file type!\n\nSupported formats: {supported_formats}\nYour file: `{filename}`", parse_mode=ParseMode.MARKDOWN)
        return

    # Set processing status
    if user_id not in user_sessions:
        user_sessions[user_id] = {'processing': False, 'preferences': {'include_ml': True, 'include_gpt': True}}
    user_sessions[user_id]['processing'] = True
    logger.info(f"User {user_id} session set to processing")
    
    # Register analysis start
    task_id = f"{user_id}_{int(time.time())}"
    resource_manager.start_analysis(user_id, task_id)

    # Acknowledge quickly and run processing in background
    progress_msg = await msg.reply_text("ğŸ“ **File received!** Starting analysis in background...")
    logger.info(f"User {user_id}: acknowledged and scheduling background worker")

    async def _worker():
        """Background worker that performs processing and messaging."""
        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                local_path = Path(tmpdir) / filename
                file = await doc.get_file()
                await file.download_to_drive(custom_path=str(local_path))
                await progress_msg.edit_text("âœ… Step 1/5: File downloaded\nâ³ Step 2/5: Processing data...")

                # Process dataset
                try:
                    outputs = await timeout_manager.run_with_timeout(
                        process_dataset,
                        str(local_path),
                        tmpdir,
                        filename,
                        user_sessions[user_id]['preferences']
                    )
                except asyncio.TimeoutError:
                    await progress_msg.edit_text("âŒ Processing timed out. Try a smaller file.")
                    return
                except Exception as e:
                    await progress_msg.edit_text(f"âŒ Error during processing: {e}")
                    return

                await progress_msg.edit_text("âœ… Step 2/5: Data processed\nâ³ Step 3/5: Generating reports...")

                # GPT summary (optional)
                if user_sessions[user_id]['preferences'].get('include_gpt', True):
                    await progress_msg.edit_text("â³ Step 4/5: AI analysis (may be skipped if API limits)")
                    cache_key = f"gpt_summary_{hash(str(outputs.get('summary_text', '')))}"
                    summary_text = cache_manager.get(cache_key)
                    if not summary_text:
                        try:
                            summary_text = await timeout_manager.run_with_timeout(
                                generate_gpt_summary,
                                outputs.get('summary_text', ''),
                                timeout=60
                            )
                            cache_manager.set(cache_key, summary_text)
                        except Exception as e:
                            logger.warning(f"GPT summary skipped/failed: {e}")
                            summary_text = None

                    if summary_text:
                        summary_file = Path(tmpdir) / "gpt_summary.txt"
                        summary_file.write_text(summary_text, encoding='utf-8')
                        outputs['files'].append(str(summary_file))

                await progress_msg.edit_text("â³ Step 5/5: Creating bundle...")

                # Bundle outputs with improved logging and fallback
                zip_path = Path(tmpdir) / "report_bundle.zip"
                try:
                    # Log files to be bundled
                    file_list = outputs.get('files', []) if isinstance(outputs, dict) else outputs
                    logger.info(f"Creating bundle for user {user_id}, {len(file_list)} files: {file_list}")

                    # Increase timeout for bundling (some reports can be large)
                    top_dir = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    await timeout_manager.run_with_timeout(
                        bundle_outputs,
                        file_list,
                        str(zip_path),
                        top_dir,
                        timeout=180
                    )

                    # Verify ZIP was created
                    if not zip_path.exists() or zip_path.stat().st_size == 0:
                        raise RuntimeError("Bundle file not created or empty")

                    await progress_msg.edit_text("âœ… Bundle created, sending results...")
                    await update.message.reply_document(
                        document=InputFile(open(zip_path, 'rb')),
                        filename=f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
                    )

                except asyncio.TimeoutError:
                    logger.exception(f"Bundle creation timed out for user {user_id}")
                    await progress_msg.edit_text("âš ï¸ Bundling timed out. Sending individual files instead...")
                    # Fallback: send individual files (skip non-existing)
                    for fp in (outputs.get('files', []) if isinstance(outputs, dict) else outputs):
                        try:
                            if Path(fp).exists():
                                await update.message.reply_document(document=InputFile(open(fp, 'rb')))
                        except Exception as exc:
                            logger.warning(f"Failed to send file {fp}: {exc}")
                    await progress_msg.edit_text("âœ… Sent available files (bundling timed out)")
                except Exception as e:
                    logger.exception(f"Bundle creation failed for user {user_id}: {e}")
                    await progress_msg.edit_text(f"âŒ Bundling failed: {e}\nAttempting to send available files...")
                    # Try to send individual files as a fallback
                    sent_any = False
                    for fp in (outputs.get('files', []) if isinstance(outputs, dict) else outputs):
                        try:
                            if Path(fp).exists():
                                await update.message.reply_document(document=InputFile(open(fp, 'rb')))
                                sent_any = True
                        except Exception as exc:
                            logger.warning(f"Failed to send file {fp}: {exc}")
                    if sent_any:
                        await progress_msg.edit_text("âœ… Sent available files (bundle failed)")
                    else:
                        await progress_msg.edit_text("âŒ No files available to send after bundle failure")

                # Store analysis info
                user_sessions[user_id]['last_analysis'] = {
                    'filename': filename,
                    'timestamp': datetime.now().isoformat(),
                    'file_count': len(outputs['files'])
                }

        finally:
            # Reset processing status and end analysis
            if user_id in user_sessions:
                user_sessions[user_id]['processing'] = False
            resource_manager.end_analysis(user_id)

    # Start background worker; don't await it here to keep handler responsive
    asyncio.create_task(_worker())
    return

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = """
ğŸ¤– **Thedsci Bot- Help**

**ğŸ“‹ Commands:**
â€¢ `/start` - Welcome message and main menu
â€¢ `/help` - Show this help message
â€¢ `/settings` - Configure analysis preferences
â€¢ `/status` - Check processing status
â€¢ `/history` - View your analysis history

**ğŸ“Š How to use:**
1. Send me a CSV or XLSX file as a document
2. I'll automatically analyze it and generate reports
3. Receive a ZIP file with comprehensive results

**ğŸ”§ Features:**
â€¢ **Data Cleaning** - Automatic duplicate removal and missing value handling
â€¢ **Exploratory Analysis** - Interactive HTML reports with visualizations
â€¢ **Machine Learning** - Optional ML model training and evaluation
â€¢ **AI Insights** - GPT-powered analysis summaries and recommendations
â€¢ **Multiple Formats** - HTML, PDF, and CSV outputs

**ğŸ“ Supported Files:**
â€¢ CSV files (`.csv`)
â€¢ Excel files (`.xlsx`, `.xls`)
â€¢ Maximum size: 20MB

**âš™ï¸ Customization:**
Use `/settings` to enable/disable:
â€¢ Machine learning model training
â€¢ AI-powered summaries
â€¢ Advanced statistical tests

Need more help? Just ask! ğŸš€
"""
    await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

async def settings_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id not in user_sessions:
        user_sessions[user_id] = {'processing': False, 'preferences': {'include_ml': True, 'include_gpt': True}}
    
    prefs = user_sessions[user_id]['preferences']
    
    settings_text = f"""
âš™ï¸ **Settings & Preferences**

**Current Settings:**
â€¢ ğŸ¤– Machine Learning: {'âœ… Enabled' if prefs.get('include_ml', True) else 'âŒ Disabled'}
â€¢ ğŸ’¡ AI Summaries: {'âœ… Enabled' if prefs.get('include_gpt', True) else 'âŒ Disabled'}
â€¢ ğŸ“Š Advanced Stats: {'âœ… Enabled' if prefs.get('include_advanced_stats', True) else 'âŒ Disabled'}

**What each setting does:**
â€¢ **ML Models** - Train classification/regression models on your data
â€¢ **AI Summaries** - Generate GPT-powered insights and recommendations
â€¢ **Advanced Stats** - Include correlation analysis, statistical tests, and outlier detection

Use the buttons below to toggle settings:
"""
    
    keyboard = [
        [InlineKeyboardButton(
            f"ğŸ¤– ML Models: {'ON' if prefs.get('include_ml', True) else 'OFF'}",
            callback_data="toggle_ml"
        )],
        [InlineKeyboardButton(
            f"ğŸ’¡ AI Summaries: {'ON' if prefs.get('include_gpt', True) else 'OFF'}",
            callback_data="toggle_gpt"
        )],
        [InlineKeyboardButton(
            f"ğŸ“Š Advanced Stats: {'ON' if prefs.get('include_advanced_stats', True) else 'OFF'}",
            callback_data="toggle_stats"
        )],
        [InlineKeyboardButton("ğŸ”™ Back to Main Menu", callback_data="main_menu")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(settings_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)

async def status_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if user_id not in user_sessions:
        await update.message.reply_text("âŒ No session found. Use /start to begin!")
        return
    
    session = user_sessions[user_id]
    
    if session.get('processing', False):
        status_text = "â³ **Processing Status:** Currently analyzing a dataset...\n\nPlease wait for the current analysis to complete."
    else:
        status_text = "âœ… **Processing Status:** Ready for new analysis\n\n"
        
        if session.get('last_analysis'):
            last = session['last_analysis']
            status_text += f"**Last Analysis:**\n"
            status_text += f"â€¢ File: `{last['filename']}`\n"
            status_text += f"â€¢ Time: {last['timestamp']}\n"
            status_text += f"â€¢ Files generated: {last['file_count']}\n"
        else:
            status_text += "No previous analyses found."
    
    await update.message.reply_text(status_text, parse_mode=ParseMode.MARKDOWN)

async def history_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if user_id not in user_sessions or not user_sessions[user_id].get('last_analysis'):
        await update.message.reply_text("ğŸ“Š **Analysis History:** No previous analyses found.\n\nUpload a dataset to get started!")
        return
    
    last = user_sessions[user_id]['last_analysis']
    history_text = f"""
ğŸ“Š **Analysis History**

**Most Recent Analysis:**
â€¢ ğŸ“ **File:** `{last['filename']}`
â€¢ ğŸ•’ **Date:** {last['timestamp']}
â€¢ ğŸ“ˆ **Files Generated:** {last['file_count']}

**Note:** Currently only showing the most recent analysis. Full history tracking coming soon!
"""
    
    await update.message.reply_text(history_text, parse_mode=ParseMode.MARKDOWN)

async def system_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show system status and performance metrics"""
    try:
        health = await check_system_health()
        
        status_emoji = {
            'healthy': 'âœ…',
            'warning': 'âš ï¸',
            'critical': 'ğŸš¨'
        }
        
        status_text = f"""
{status_emoji.get(health['status'], 'â“')} **System Status: {health['status'].upper()}**

**ğŸ“Š Performance Metrics:**
â€¢ ğŸ§  Memory: {health['performance']['memory_percent']:.1f}% ({health['performance']['memory_trend']})
â€¢ âš¡ CPU: {health['performance']['cpu_percent']:.1f}% ({health['performance']['cpu_trend']})
â€¢ ğŸ’¾ Disk: {health['performance']['disk_percent']:.1f}%
â€¢ â±ï¸ Uptime: {health['performance']['uptime']//3600:.0f}h {(health['performance']['uptime']%3600)//60:.0f}m

**ğŸ“ˆ Analysis Statistics:**
â€¢ ğŸ“Š Total Analyses: {health['performance']['total_analyses']}
â€¢ âœ… Success Rate: {health['performance']['success_rate']:.1%}
â€¢ â±ï¸ Avg Time: {health['performance']['avg_processing_time']:.1f}s
â€¢ âš ï¸ Timeout Rate: {health['performance']['timeout_rate']:.1%}

**ğŸ”„ Resource Status:**
â€¢ ğŸ”„ Active: {health['resources']['active_tasks']}/{health['resources']['max_concurrent']}
â€¢ â±ï¸ Task Ages: {', '.join(f'{age:.0f}s' for age in health['resources']['task_ages'].values()) if health['resources']['task_ages'] else 'None'}
â€¢ ğŸ†• Can Accept: {'âœ…' if health['resources']['can_accept_new'] else 'âŒ'}

**ğŸ’¾ Cache Status:**
â€¢ ğŸ“¦ Size: {health['cache']['size']}/{health['cache']['max_size']}
â€¢ ğŸ¯ Hit Rate: {health['cache']['hit_rate']:.1%}
â€¢ â° TTL: {health['cache']['ttl']}s

**ğŸ”§ System Recommendations:**
{chr(10).join(f'â€¢ {r}' for r in health['recommendations'])}

*Last updated: {health['timestamp']}*
"""
        
        await update.message.reply_text(status_text, parse_mode=ParseMode.MARKDOWN)
        
    except Exception as e:
        logger.error(f"Error getting system status: {e}")
        await update.message.reply_text("âŒ **Error retrieving system status.**\n\nPlease try again later.")

async def callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    data = query.data
    
    if data == "upload":
        await query.edit_message_text("ğŸ“Š **Upload a Dataset**\n\nSend me a CSV or XLSX file as a document to analyze it!\n\nSupported formats: `.csv`, `.xlsx`, `.xls`\nMaximum size: 20MB", parse_mode=ParseMode.MARKDOWN)
    
    elif data == "settings":
        if user_id not in user_sessions:
            user_sessions[user_id] = {'processing': False, 'preferences': {'include_ml': True, 'include_gpt': True}}
        
        prefs = user_sessions[user_id]['preferences']
        
        settings_text = f"""
âš™ï¸ **Settings & Preferences**

**Current Settings:**
â€¢ ğŸ¤– Machine Learning: {'âœ… Enabled' if prefs.get('include_ml', True) else 'âŒ Disabled'}
â€¢ ğŸ’¡ AI Summaries: {'âœ… Enabled' if prefs.get('include_gpt', True) else 'âŒ Disabled'}
â€¢ ğŸ“Š Advanced Stats: {'âœ… Enabled' if prefs.get('include_advanced_stats', True) else 'âŒ Disabled'}

Use the buttons below to toggle settings:
"""
        
        keyboard = [
            [InlineKeyboardButton(
                f"ğŸ¤– ML Models: {'ON' if prefs.get('include_ml', True) else 'OFF'}", 
                callback_data="toggle_ml"
            )],
            [InlineKeyboardButton(
                f"ğŸ’¡ AI Summaries: {'ON' if prefs.get('include_gpt', True) else 'OFF'}", 
                callback_data="toggle_gpt"
            )],
            [InlineKeyboardButton(
                f"ğŸ“Š Advanced Stats: {'ON' if prefs.get('include_advanced_stats', True) else 'OFF'}", 
                callback_data="toggle_stats"
            )],
            [InlineKeyboardButton("ğŸ”™ Back to Main Menu", callback_data="main_menu")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await query.edit_message_text(settings_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)
    
    elif data == "help":
        help_text = """
ğŸ¤– **Thedsci Bot - Help**

**ğŸ“‹ Commands:**
â€¢ `/start` - Welcome message and main menu
â€¢ `/help` - Show this help message
â€¢ `/settings` - Configure analysis preferences
â€¢ `/status` - Check processing status
â€¢ `/history` - View your analysis history

**ğŸ“Š How to use:**
1. Send me a CSV or XLSX file as a document
2. I'll automatically analyze it and generate reports
3. Receive a ZIP file with comprehensive results

**ğŸ”§ Features:**
â€¢ **Data Cleaning** - Automatic duplicate removal and missing value handling
â€¢ **Exploratory Analysis** - Interactive HTML reports with visualizations
â€¢ **Machine Learning** - Optional ML model training and evaluation
â€¢ **AI Insights** - GPT-powered analysis summaries and recommendations
â€¢ **Multiple Formats** - HTML, PDF, and CSV outputs

**ğŸ“ Supported Files:**
â€¢ CSV files (`.csv`)
â€¢ Excel files (`.xlsx`, `.xls`)
â€¢ Maximum size: 20MB

Need more help? Just ask! ğŸš€
"""
        keyboard = [[InlineKeyboardButton("ğŸ”™ Back to Main Menu", callback_data="main_menu")]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(help_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)
    
    elif data == "sample":
        sample_text = """
ğŸ“ˆ **Sample Analysis**

Here's what a typical analysis includes:

**ğŸ“Š Data Overview:**
â€¢ Dataset shape and basic statistics
â€¢ Data types and missing value analysis
â€¢ Duplicate detection and removal

**ğŸ” Exploratory Analysis:**
â€¢ Interactive visualizations (histograms, scatter plots, heatmaps)
â€¢ Correlation analysis between variables
â€¢ Outlier detection and analysis
â€¢ Distribution analysis

**ğŸ¤– Machine Learning (if enabled):**
â€¢ Automatic model selection (classification/regression)
â€¢ Model performance metrics
â€¢ Feature importance analysis
â€¢ Model artifacts for future use

**ğŸ’¡ AI Insights (if enabled):**
â€¢ Natural language summary of findings
â€¢ Actionable recommendations
â€¢ Data quality assessment
â€¢ Next steps suggestions

**ğŸ“ Output Files:**
â€¢ Interactive HTML report
â€¢ PDF version of the report
â€¢ Cleaned dataset (CSV)
â€¢ Model files and metrics
â€¢ AI summary document

Ready to analyze your own data? Send me a file! ğŸš€
"""
        keyboard = [[InlineKeyboardButton("ğŸ”™ Back to Main Menu", callback_data="main_menu")]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(sample_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)
    
    elif data == "main_menu":
        welcome_text = """
ğŸ¤– **Welcome to Data Science Bot Enhanced!**

I'm your AI-powered data analysis assistant. I can help you:

ğŸ“Š **Analyze your datasets** - Upload CSV/XLSX files
ğŸ” **Generate insights** - Automatic EDA and statistical analysis  
ğŸ¤– **Build ML models** - Classification and regression models
ğŸ“ˆ **Create reports** - Beautiful HTML/PDF reports with visualizations
ğŸ’¡ **AI summaries** - GPT-powered insights and recommendations

**How to use:**
1. Send me a CSV or XLSX file as a document
2. I'll analyze it and send back a comprehensive report
3. Use /settings to customize your analysis preferences

Ready to analyze some data? Just send me a file! ğŸš€
"""
        
        keyboard = [
            [InlineKeyboardButton("ğŸ“Š Upload Dataset", callback_data="upload")],
            [InlineKeyboardButton("âš™ï¸ Settings", callback_data="settings"),
             InlineKeyboardButton("â“ Help", callback_data="help")],
            [InlineKeyboardButton("ğŸ“ˆ Sample Analysis", callback_data="sample")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(welcome_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)
    
    elif data.startswith("toggle_"):
        if user_id not in user_sessions:
            user_sessions[user_id] = {'processing': False, 'preferences': {'include_ml': True, 'include_gpt': True}}
        
        setting = data.replace("toggle_", "")
        current_value = user_sessions[user_id]['preferences'].get(f'include_{setting}', True)
        user_sessions[user_id]['preferences'][f'include_{setting}'] = not current_value
        
        # Show updated settings
        prefs = user_sessions[user_id]['preferences']
        
        settings_text = f"""
âš™ï¸ **Settings & Preferences**

**Current Settings:**
â€¢ ğŸ¤– Machine Learning: {'âœ… Enabled' if prefs.get('include_ml', True) else 'âŒ Disabled'}
â€¢ ğŸ’¡ AI Summaries: {'âœ… Enabled' if prefs.get('include_gpt', True) else 'âŒ Disabled'}
â€¢ ğŸ“Š Advanced Stats: {'âœ… Enabled' if prefs.get('include_advanced_stats', True) else 'âŒ Disabled'}

Use the buttons below to toggle settings:
"""
        
        keyboard = [
            [InlineKeyboardButton(
                f"ğŸ¤– ML Models: {'ON' if prefs.get('include_ml', True) else 'OFF'}", 
                callback_data="toggle_ml"
            )],
            [InlineKeyboardButton(
                f"ğŸ’¡ AI Summaries: {'ON' if prefs.get('include_gpt', True) else 'OFF'}", 
                callback_data="toggle_gpt"
            )],
            [InlineKeyboardButton(
                f"ğŸ“Š Advanced Stats: {'ON' if prefs.get('include_advanced_stats', True) else 'OFF'}", 
                callback_data="toggle_stats"
            )],
            [InlineKeyboardButton("ğŸ”™ Back to Main Menu", callback_data="main_menu")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await query.edit_message_text(settings_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)


async def post_init(application):
    """Set bot commands after initialization"""
    try:
        commands = [
            BotCommand("start", "ğŸš€ Start the bot and show main menu"),
            BotCommand("help", "â“ Show help and usage instructions"),
            BotCommand("settings", "âš™ï¸ Configure analysis preferences"),
            BotCommand("status", "ğŸ“Š Check current processing status"),
            BotCommand("history", "ğŸ“ˆ View analysis history"),
            BotCommand("system", "ğŸ”§ Show system status and performance")
        ]
        await application.bot.set_my_commands(commands)
        logger.info("âœ… Bot commands configured successfully")
    except Exception as e:
        logger.error(f"âŒ Error setting bot commands: {e}")

def main():
    try:
        if not TELEGRAM_TOKEN:
            raise RuntimeError('TELEGRAM_TOKEN not set in env')
        
        logger.info("ğŸ”§ Building application...")
        app = ApplicationBuilder().token(TELEGRAM_TOKEN).post_init(post_init).build()
        
        logger.info("ğŸ“ Adding command handlers...")
        # Command handlers
        app.add_handler(CommandHandler('start', start))
        app.add_handler(CommandHandler('help', help_cmd))
        app.add_handler(CommandHandler('settings', settings_cmd))
        app.add_handler(CommandHandler('status', status_cmd))
        app.add_handler(CommandHandler('history', history_cmd))
        app.add_handler(CommandHandler('system', system_cmd))
        
        # Callback query handler for interactive buttons
        app.add_handler(CallbackQueryHandler(callback_handler))
        
        # Message handlers
        app.add_handler(MessageHandler(filters.Document.ALL & ~filters.COMMAND, handle_file))
        
        logger.info("ğŸ¤– Data Science Bot Enhanced starting (polling mode)...")
        logger.info("ğŸ“Š Features: Interactive UI, Progress tracking, Settings, ML models, AI summaries")
        logger.info("ğŸš€ Starting polling...")
        
        app.run_polling()
        
    except Exception as e:
        logger.error(f"âŒ Fatal error in main: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == '__main__':
    main()
